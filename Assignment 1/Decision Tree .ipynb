{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from math import log\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Feature Discrete Output Decision Tree for Classification\n",
    "Note - Please rename output variable to be 'Class' in your dataset for this implementation to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(target):\n",
    "    freq = {}\n",
    "    for elem in target:\n",
    "        if elem not in freq:\n",
    "            freq[elem]=1/len(target)\n",
    "        else: \n",
    "            freq[elem]+=1/len(target)\n",
    "    _sum = [-freq[i]*np.log2(freq[i]) for i in freq]\n",
    "    return sum(_sum)\n",
    "\n",
    "def info_gain(data,attributes):\n",
    "    entropy_dataset = entropy(data['Class'])\n",
    "    entr_val = {}\n",
    "    infg = {}\n",
    "    for attr in attributes:\n",
    "        freq = {}\n",
    "        for i in data[attr]:\n",
    "            if i not in freq:\n",
    "                freq[i]=1/len(data[attr])\n",
    "            else:\n",
    "                freq[i]+=1/len(data[attr])\n",
    "        keys = list(freq.keys())\n",
    "        entr = {}\n",
    "        for i in keys:\n",
    "            temp = len(data[data[attr]==i])\n",
    "            entr[i] = temp/len(data)*entropy(data[data[attr]==i]['Class'])\n",
    "        entr_val[attr] = sum(list(entr.values()))\n",
    "        infg[attr] = entropy_dataset - entr_val[attr]\n",
    "    return max(infg, key = infg.get)\n",
    "\n",
    "def dtree(dataset,data,attributes,parent):\n",
    "    attribute = [i for i in attributes]\n",
    "    if len(data['Class'].unique())<=1:\n",
    "        return (list(data['Class'].unique())[0])\n",
    "    elif len(data)==0:\n",
    "        return np.unique(data['Class'])[np.argmax(np.unique(data['Class'],return_counts=True)[1])]\n",
    "    elif len(attribute)==0:\n",
    "        return parent\n",
    "    else:\n",
    "        parent = np.unique(data['Class'])[np.argmax(np.unique(data['Class'],return_counts=True)[1])]\n",
    "        \n",
    "    best = info_gain(data,attribute)\n",
    "    tree = {best:{}}\n",
    "    attribute.remove(best)\n",
    "    for ndata in data[best].unique():\n",
    "        new_data = data[data[best]==ndata]\n",
    "        subtree = dtree(dataset,new_data,attribute,parent)\n",
    "        tree[best][ndata]=subtree\n",
    "    return tree  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Features Discrete Output Decision Tree for Classification\n",
    "The code was majorly referred from this link here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iris Dataset Classification\n",
    "def gini(splits,classes):\n",
    "    total_rows = 0\n",
    "    final = 0\n",
    "    for i in range(len(splits)):\n",
    "        total_rows+=len(splits[i])\n",
    "    final = 0\n",
    "    for split in splits:\n",
    "        if len(split)==0:\n",
    "            continue\n",
    "        gscore = 0\n",
    "        for cls in classes:\n",
    "            p = [row[-1] for row in split].count(cls)/len(split)\n",
    "            gscore+=p*p\n",
    "        final+= (1-gscore)*(len(split)/total_rows)\n",
    "    return final\n",
    "## This needs to be done very carefully\n",
    "## Binary Splits\n",
    "def divide_data(dataset,feature,threshold):\n",
    "    new_data1 = []\n",
    "    new_data2 = []\n",
    "    for elem in dataset:\n",
    "        if elem[feature]<threshold:\n",
    "            new_data1.append(elem)\n",
    "        else:\n",
    "            new_data2.append(elem)\n",
    "    return new_data1, new_data2\n",
    "\n",
    "def best_split(dataset,classes):\n",
    "    best_so_far = 1000\n",
    "    best_splits = None\n",
    "    feature = 1000\n",
    "    value_split = 1000\n",
    "    for i in range(len(dataset[0])-1):\n",
    "        for elem in dataset:\n",
    "            splits = divide_data(dataset,i,elem[i])\n",
    "            gscore = gini(splits,classes)\n",
    "            if gscore<best_so_far:\n",
    "                best_so_far = gscore\n",
    "                best_splits = splits\n",
    "                feature = i\n",
    "                value_split = elem[i]\n",
    "    return {'split':best_splits,'Feature':feature,'Value':value_split}\n",
    "### Metrics Done _ Build Tree now .....\n",
    "def leaf_node(split):\n",
    "    cls = [elem[-1] for elem in split]\n",
    "    # Take Majority Vote\n",
    "    count = {}\n",
    "    for i in cls:\n",
    "        if i not in count:\n",
    "            count[i]=1\n",
    "        else:\n",
    "            count[i]+=1\n",
    "    return max(count, key = count.get)\n",
    "\n",
    "def partition(node, maxdepth, minsize, depth):\n",
    "    ## Each partition from above gives a node in essence.\n",
    "    lchild, rchild = node['split']\n",
    "    if not lchild or not rchild:\n",
    "        node['left']= leaf_node(lchild+rchild)\n",
    "        node['right'] = leaf_node(lchild+rchild)\n",
    "        return\n",
    "    if depth>maxdepth:\n",
    "        node['left'] = leaf_node(lchild)\n",
    "        node['right'] = leaf_node(rchild)\n",
    "        return\n",
    "    if len(lchild)<=minsize:\n",
    "        node['left'] = leaf_node(lchild)\n",
    "    else:\n",
    "        node['left'] = best_split(lchild,cls)\n",
    "        partition(node['left'],maxdepth,minsize, depth+1)\n",
    "    if len(rchild)<=minsize:\n",
    "        node['right'] = leaf_node(rchild)\n",
    "    else:\n",
    "        node['right'] = best_split(rchild,cls)\n",
    "        partition(node['right'],maxdepth,minsize,depth+1)\n",
    "        \n",
    "def print_tree(node,depth):\n",
    "    if type(node)==dict:\n",
    "        print('%s[X%d < %.3f]' % ((depth*' ', (node['Feature']+1), node['Value'])))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('Depth - %s[%s]' % ((depth*' ', node)),depth)\n",
    "\n",
    "\n",
    "def tree_iris(dataset, maxdepth, minsize):\n",
    "    root = best_split(dataset,cls)\n",
    "    partition(root,maxdepth,minsize,1)\n",
    "    ## Printing the made Decision Tree\n",
    "    return root\n",
    "\n",
    "def predict(node, row):\n",
    "\tif row[node['Feature']] < node['Value']:\n",
    "\t\tif isinstance(node['left'], dict):\n",
    "\t\t\treturn predict(node['left'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['left']\n",
    "\telse:\n",
    "\t\tif isinstance(node['right'], dict):\n",
    "\t\t\treturn predict(node['right'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['right']\n",
    "\n",
    "\n",
    "\"\"\"def predict(node, elem):\n",
    "#     print(node,elem)\n",
    "    if elem[node['Feature']]<node['Value']:\n",
    "#         print(node['Value'],elem[node['Feature']])\n",
    "        \n",
    "        if type(node['left'])==dict:\n",
    "            predict(node['left'],elem)\n",
    "        else:\n",
    "#             print('---printining left---',node['left'])\n",
    "            return node['left']\n",
    "    else:\n",
    "#         print('Greater than')\n",
    "        if type((node['right']))==dict:\n",
    "            predict(node['right'],elem)\n",
    "        else:\n",
    "#             print('---printining right ---',node['right'])\n",
    "            return node['right']\"\"\"\n",
    "def class_aggregate(dataset):\n",
    "    temp = []\n",
    "    for i in range(len(dataset)):\n",
    "        temp.append(dataset[i][-1])\n",
    "    temp = np.unique(np.array(temp))\n",
    "    return temp\n",
    "cls = class_aggregate(np.array(df))\n",
    "cls = np.uint8(cls)\n",
    "def val_replace(cls,dataset):\n",
    "    for i in range(len(cls)):\n",
    "        dataset = dataset.replace(cls[i],i)\n",
    "    return dataset\n",
    "df = val_replace(cls,df)\n",
    "\n",
    "def accurate(test,tree):\n",
    "    temp = 0\n",
    "    for i in test:\n",
    "        val = predict(tree,i)\n",
    "        if i[-1]==val:\n",
    "            temp+=1\n",
    "    return temp/len(test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.11111111111111\n",
      "88.88888888888889\n",
      "93.33333333333333\n",
      "93.33333333333333\n",
      "95.55555555555556\n",
      "91.11111111111111\n",
      "93.33333333333333\n",
      "95.55555555555556\n",
      "91.11111111111111\n",
      "91.11111111111111\n",
      "97.77777777777777\n",
      "95.55555555555556\n",
      "93.33333333333333\n",
      "88.88888888888889\n",
      "88.88888888888889\n",
      "88.88888888888889\n",
      "95.55555555555556\n",
      "97.77777777777777\n",
      "95.55555555555556\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    s =0\n",
    "    for j in range(100):\n",
    "        train, test = train_test_split(np.array(df),test_size = .30,random_state = j)\n",
    "        tree = tree_iris(train,i,0)\n",
    "        s+=(accurate(test,tree))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(k,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
