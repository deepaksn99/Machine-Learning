{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from math import log\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Feature Discrete Output Decision Tree for Classification\n",
    "Note - Please rename output variable to be 'Class' in your dataset for this implementation to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(target):\n",
    "    freq = {}\n",
    "    for elem in target:\n",
    "        if elem not in freq:\n",
    "            freq[elem]=1/len(target)\n",
    "        else: \n",
    "            freq[elem]+=1/len(target)\n",
    "    _sum = [-freq[i]*np.log2(freq[i]) for i in freq]\n",
    "    return sum(_sum)\n",
    "\n",
    "def info_gain(data,attributes):\n",
    "    entropy_dataset = entropy(data['Class'])\n",
    "    entr_val = {}\n",
    "    infg = {}\n",
    "    for attr in attributes:\n",
    "        freq = {}\n",
    "        for i in data[attr]:\n",
    "            if i not in freq:\n",
    "                freq[i]=1/len(data[attr])\n",
    "            else:\n",
    "                freq[i]+=1/len(data[attr])\n",
    "        keys = list(freq.keys())\n",
    "        entr = {}\n",
    "        for i in keys:\n",
    "            temp = len(data[data[attr]==i])\n",
    "            entr[i] = temp/len(data)*entropy(data[data[attr]==i]['Class'])\n",
    "        entr_val[attr] = sum(list(entr.values()))\n",
    "        infg[attr] = entropy_dataset - entr_val[attr]\n",
    "    return max(infg, key = infg.get)\n",
    "\n",
    "def dtree(dataset,data,attributes,parent):\n",
    "    attribute = [i for i in attributes]\n",
    "    if len(data['Class'].unique())<=1:\n",
    "        return (list(data['Class'].unique())[0])\n",
    "    elif len(data)==0:\n",
    "        return np.unique(data['Class'])[np.argmax(np.unique(data['Class'],return_counts=True)[1])]\n",
    "    elif len(attribute)==0:\n",
    "        return parent\n",
    "    else:\n",
    "        parent = np.unique(data['Class'])[np.argmax(np.unique(data['Class'],return_counts=True)[1])]\n",
    "        \n",
    "    best = info_gain(data,attribute)\n",
    "    tree = {best:{}}\n",
    "    attribute.remove(best)\n",
    "    for ndata in data[best].unique():\n",
    "        new_data = data[data[best]==ndata]\n",
    "        subtree = dtree(dataset,new_data,attribute,parent)\n",
    "        tree[best][ndata]=subtree\n",
    "    return tree  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Features Discrete Output Decision Tree for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iris Dataset Classification\n",
    "def gini(splits,classes):\n",
    "    total_rows = 0\n",
    "    final = 0\n",
    "    for i in range(len(splits)):\n",
    "        total_rows+=len(splits[i])\n",
    "    final = 0\n",
    "    for split in splits:\n",
    "        if len(split)==0:\n",
    "            continue\n",
    "        gscore = 0\n",
    "        for cls in classes:\n",
    "            p = [row[-1] for row in split].count(cls)/len(split)\n",
    "            gscore+=p*p\n",
    "        final+= (1-gscore)*(len(split)/total_rows)\n",
    "    return final\n",
    "## This needs to be done very carefully\n",
    "## Binary Splits\n",
    "def divide_data(dataset,feature,threshold):\n",
    "    new_data1 = []\n",
    "    new_data2 = []\n",
    "    for elem in dataset:\n",
    "        if elem[feature]<threshold:\n",
    "            new_data1.append(elem)\n",
    "        else:\n",
    "            new_data2.append(elem)\n",
    "    return new_data1, new_data2\n",
    "\n",
    "def best_split(dataset,classes):\n",
    "    best_so_far = 1000\n",
    "    best_splits = None\n",
    "    feature = 1000\n",
    "    value_split = 1000\n",
    "    for i in range(len(dataset[0])-1):\n",
    "        for elem in dataset:\n",
    "            splits = divide_data(dataset,i,elem[i])\n",
    "            gscore = gini(splits,classes)\n",
    "            if gscore<best_so_far:\n",
    "                best_so_far = gscore\n",
    "                best_splits = splits\n",
    "                feature = i+1\n",
    "                value_split = elem[i]\n",
    "    return {'split':best_splits,'Feature':feature,'Value':value_split}\n",
    "### Metrics Done _ Build Tree now .....\n",
    "def leaf_node(split):\n",
    "    cls = [elem[-1] for elem in split]\n",
    "    # Take Majority Vote\n",
    "    count = {}\n",
    "    for i in cls:\n",
    "        if i not in count:\n",
    "            count[i]=1\n",
    "        else:\n",
    "            count[i]+=1\n",
    "    return max(count, key = count.get)\n",
    "\n",
    "def partition(node, maxdepth, minsize, depth):\n",
    "    ## Each partition from above gives a node in essence.\n",
    "    lchild, rchild = node['split']\n",
    "    if not lchild or not rchild:\n",
    "        node['left']= leaf_node(lchild+rchild)\n",
    "        node['right'] = leaf_node(lchild+rchild)\n",
    "        return\n",
    "    if depth>maxdepth:\n",
    "        node['left'] = leaf_node(lchild)\n",
    "        node['right'] = leaf_node(rchild)\n",
    "    if len(lchild)<=minsize:\n",
    "        node['left'] = leaf_node(lchild)\n",
    "    else:\n",
    "        node['left'] = best_split(lchild,cls)\n",
    "        partition(node['left'],maxdepth,minsize, depth+1)\n",
    "    if len(rchild)<=minsize:\n",
    "        node['right'] = leaf_node(rchild)\n",
    "    else:\n",
    "        node['right'] = best_split(rchild,cls)\n",
    "        partition(node['right'],maxdepth,minsize,depth+1)\n",
    "        \n",
    "def print_tree(node,depth):\n",
    "    if type(node)==dict:\n",
    "        print('%s[X%d < %.3f]' % ((depth*' ', (node['Feature']), node['Value'])))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))\n",
    "\n",
    "\n",
    "def tree_iris(dataset, maxdepth, minsize):\n",
    "    root = best_split(dataset,cls)\n",
    "    partition(root,maxdepth,minsize,1)\n",
    "    ## Printing the made Decision Tree\n",
    "    return root\n",
    "\n",
    "def predict(node, row):\n",
    "\tif row[node['Feature']] < node['Value']:\n",
    "\t\tif isinstance(node['left'], dict):\n",
    "\t\t\treturn predict(node['left'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['left']\n",
    "\telse:\n",
    "\t\tif isinstance(node['right'], dict):\n",
    "\t\t\treturn predict(node['right'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['right']\n",
    "\n",
    "\n",
    "\"\"\"def predict(node, elem):\n",
    "#     print(node,elem)\n",
    "    if elem[node['Feature']]<node['Value']:\n",
    "#         print(node['Value'],elem[node['Feature']])\n",
    "        \n",
    "        if type(node['left'])==dict:\n",
    "            predict(node['left'],elem)\n",
    "        else:\n",
    "#             print('---printining left---',node['left'])\n",
    "            return node['left']\n",
    "    else:\n",
    "#         print('Greater than')\n",
    "        if type((node['right']))==dict:\n",
    "            predict(node['right'],elem)\n",
    "        else:\n",
    "#             print('---printining right ---',node['right'])\n",
    "            return node['right']\"\"\"\n",
    "def class_aggregate(dataset):\n",
    "    temp = []\n",
    "    for i in range(len(dataset)):\n",
    "        temp.append(dataset[i][-1])\n",
    "    temp = np.unique(np.array(temp))\n",
    "    return temp\n",
    "cls = class_aggregate(np.array(df))\n",
    "cls = np.uint8(cls)\n",
    "def val_replace(cls,dataset):\n",
    "    for i in range(len(cls)):\n",
    "        dataset = dataset.replace(cls[i],i)\n",
    "    return dataset\n",
    "df = val_replace(cls,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(np.array(df),test_size = .30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = tree_iris(train,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for i in test:\n",
    "    print(predict(tree,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.7, 2.8, 4.5, 1.3, 1. ],\n",
       "       [6.4, 2.8, 5.6, 2.2, 2. ],\n",
       "       [5.6, 3. , 4.1, 1.3, 1. ],\n",
       "       [5.3, 3.7, 1.5, 0.2, 0. ],\n",
       "       [6.1, 3. , 4.9, 1.8, 2. ],\n",
       "       [5. , 2. , 3.5, 1. , 1. ],\n",
       "       [6.5, 3. , 5.8, 2.2, 2. ],\n",
       "       [4.8, 3.4, 1.9, 0.2, 0. ],\n",
       "       [6. , 2.2, 5. , 1.5, 2. ],\n",
       "       [6.1, 2.6, 5.6, 1.4, 2. ],\n",
       "       [6.3, 3.3, 6. , 2.5, 2. ],\n",
       "       [6.2, 2.2, 4.5, 1.5, 1. ],\n",
       "       [4.5, 2.3, 1.3, 0.3, 0. ],\n",
       "       [6. , 2.2, 4. , 1. , 1. ],\n",
       "       [7.2, 3.2, 6. , 1.8, 2. ],\n",
       "       [4.9, 2.4, 3.3, 1. , 1. ],\n",
       "       [5.5, 2.4, 3.7, 1. , 1. ],\n",
       "       [7.3, 2.9, 6.3, 1.8, 2. ],\n",
       "       [5.5, 2.3, 4. , 1.3, 1. ],\n",
       "       [7.7, 3.8, 6.7, 2.2, 2. ],\n",
       "       [4.3, 3. , 1.1, 0.1, 0. ],\n",
       "       [5.7, 2.5, 5. , 2. , 2. ],\n",
       "       [5.1, 2.5, 3. , 1.1, 1. ],\n",
       "       [6.3, 3.3, 4.7, 1.6, 1. ],\n",
       "       [7.2, 3. , 5.8, 1.6, 2. ],\n",
       "       [4.6, 3.6, 1. , 0.2, 0. ],\n",
       "       [7.7, 2.8, 6.7, 2. , 2. ],\n",
       "       [6.3, 2.5, 4.9, 1.5, 1. ],\n",
       "       [6.7, 3.1, 4.7, 1.5, 1. ],\n",
       "       [5.4, 3.4, 1.7, 0.2, 0. ],\n",
       "       [7.7, 2.6, 6.9, 2.3, 2. ],\n",
       "       [5.1, 3.3, 1.7, 0.5, 0. ],\n",
       "       [6.3, 3.4, 5.6, 2.4, 2. ],\n",
       "       [6.3, 2.5, 5. , 1.9, 2. ],\n",
       "       [6.8, 3.2, 5.9, 2.3, 2. ],\n",
       "       [6.7, 3.3, 5.7, 2.1, 2. ],\n",
       "       [6.7, 3.1, 4.4, 1.4, 1. ],\n",
       "       [5.1, 3.8, 1.6, 0.2, 0. ],\n",
       "       [6.2, 2.9, 4.3, 1.3, 1. ],\n",
       "       [4.8, 3.1, 1.6, 0.2, 0. ],\n",
       "       [5.8, 2.6, 4. , 1.2, 1. ],\n",
       "       [7.2, 3.6, 6.1, 2.5, 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.1, 2. ],\n",
       "       [6.7, 3.1, 5.6, 2.4, 2. ],\n",
       "       [4.8, 3. , 1.4, 0.3, 0. ],\n",
       "       [5.4, 3.9, 1.3, 0.4, 0. ],\n",
       "       [4.4, 3.2, 1.3, 0.2, 0. ],\n",
       "       [5. , 2.3, 3.3, 1. , 1. ],\n",
       "       [5.4, 3.9, 1.7, 0.4, 0. ],\n",
       "       [5. , 3.5, 1.3, 0.3, 0. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
       "       [5.1, 3.5, 1.4, 0.3, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [7.6, 3. , 6.6, 2.1, 2. ],\n",
       "       [4.6, 3.4, 1.4, 0.3, 0. ],\n",
       "       [5.7, 2.9, 4.2, 1.3, 1. ],\n",
       "       [7. , 3.2, 4.7, 1.4, 1. ],\n",
       "       [5.1, 3.8, 1.5, 0.3, 0. ],\n",
       "       [5.7, 3. , 4.2, 1.2, 1. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
       "       [5.2, 4.1, 1.5, 0.1, 0. ],\n",
       "       [5.5, 2.6, 4.4, 1.2, 1. ],\n",
       "       [5.7, 2.8, 4.1, 1.3, 1. ],\n",
       "       [6.1, 2.8, 4. , 1.3, 1. ],\n",
       "       [5.9, 3. , 5.1, 1.8, 2. ],\n",
       "       [5.4, 3. , 4.5, 1.5, 1. ],\n",
       "       [5. , 3.4, 1.6, 0.4, 0. ],\n",
       "       [6.3, 2.9, 5.6, 1.8, 2. ],\n",
       "       [4.9, 2.5, 4.5, 1.7, 2. ],\n",
       "       [5. , 3.6, 1.4, 0.2, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.1, 0. ],\n",
       "       [5.9, 3. , 4.2, 1.5, 1. ],\n",
       "       [6.7, 3.3, 5.7, 2.5, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3, 2. ],\n",
       "       [6.7, 3. , 5.2, 2.3, 2. ],\n",
       "       [5.5, 3.5, 1.3, 0.2, 0. ],\n",
       "       [5.8, 4. , 1.2, 0.2, 0. ],\n",
       "       [4.9, 3. , 1.4, 0.2, 0. ],\n",
       "       [5.1, 3.5, 1.4, 0.2, 0. ],\n",
       "       [4.6, 3.2, 1.4, 0.2, 0. ],\n",
       "       [5.8, 2.7, 4.1, 1. , 1. ],\n",
       "       [5.6, 2.9, 3.6, 1.3, 1. ],\n",
       "       [6.4, 2.9, 4.3, 1.3, 1. ],\n",
       "       [6.8, 3. , 5.5, 2.1, 2. ],\n",
       "       [6.9, 3.1, 5.4, 2.1, 2. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [6.7, 3. , 5. , 1.7, 1. ],\n",
       "       [5.7, 3.8, 1.7, 0.3, 0. ],\n",
       "       [5. , 3. , 1.6, 0.2, 0. ],\n",
       "       [6.4, 2.7, 5.3, 1.9, 2. ],\n",
       "       [5.2, 3.5, 1.5, 0.2, 0. ],\n",
       "       [7.9, 3.8, 6.4, 2. , 2. ],\n",
       "       [5. , 3.3, 1.4, 0.2, 0. ],\n",
       "       [6.4, 3.1, 5.5, 1.8, 2. ],\n",
       "       [6.5, 3. , 5.2, 2. , 2. ],\n",
       "       [6.5, 3.2, 5.1, 2. , 2. ],\n",
       "       [6.9, 3.1, 5.1, 2.3, 2. ],\n",
       "       [6.9, 3.1, 4.9, 1.5, 1. ],\n",
       "       [5.2, 2.7, 3.9, 1.4, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3, 1. ],\n",
       "       [7.1, 3. , 5.9, 2.1, 2. ],\n",
       "       [4.7, 3.2, 1.3, 0.2, 0. ],\n",
       "       [6.1, 2.9, 4.7, 1.4, 1. ],\n",
       "       [6. , 2.7, 5.1, 1.6, 1. ]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X3 < 3.000]\n",
      " [X1 < 5.300]\n",
      "  [X1 < 4.800]\n",
      "   [X1 < 4.500]\n",
      "    [X1 < 4.300]\n",
      "     [0.0]\n",
      "     [0.0]\n",
      "    [X1 < 4.500]\n",
      "     [0.0]\n",
      "     [0.0]\n",
      "   [X1 < 4.800]\n",
      "    [0.0]\n",
      "    [0.0]\n",
      "  [X1 < 5.300]\n",
      "   [0.0]\n",
      "   [0.0]\n",
      " [X4 < 1.800]\n",
      "  [X3 < 5.600]\n",
      "   [X1 < 5.000]\n",
      "    [X2 < 2.500]\n",
      "     [1.0]\n",
      "     [2.0]\n",
      "    [X3 < 5.000]\n",
      "     [X1 < 5.700]\n",
      "      [X1 < 5.600]\n",
      "       [X1 < 5.000]\n",
      "        [1.0]\n",
      "        [1.0]\n",
      "       [X1 < 5.600]\n",
      "        [1.0]\n",
      "        [1.0]\n",
      "      [X1 < 5.700]\n",
      "       [1.0]\n",
      "       [1.0]\n",
      "     [X2 < 2.700]\n",
      "      [2.0]\n",
      "      [X1 < 6.700]\n",
      "       [1.0]\n",
      "       [1.0]\n",
      "   [X1 < 6.100]\n",
      "    [2.0]\n",
      "    [2.0]\n",
      "  [X1 < 6.400]\n",
      "   [X1 < 6.100]\n",
      "    [X1 < 5.700]\n",
      "     [2.0]\n",
      "     [2.0]\n",
      "    [X1 < 6.100]\n",
      "     [2.0]\n",
      "     [2.0]\n",
      "   [X1 < 6.400]\n",
      "    [2.0]\n",
      "    [2.0]\n"
     ]
    }
   ],
   "source": [
    "print_tree(tree,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
