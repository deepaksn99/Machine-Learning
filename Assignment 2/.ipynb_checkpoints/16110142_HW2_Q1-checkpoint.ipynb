{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_iris()['data']\n",
    "target = load_iris()['target']\n",
    "target[:50] = 0\n",
    "target[51:100] = 1\n",
    "target[100:] = 2\n",
    "df = pd.DataFrame(dataset)\n",
    "df = df.rename( columns={0: \"SL\", 1: \"SW\", 2:\"PL\",3:\"PW\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(Target=pd.Series(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree as used in Assignment 1 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def class_aggregate(dataset):\n",
    "    temp = []\n",
    "    for i in range(len(dataset)):\n",
    "        temp.append(dataset[i][-1])\n",
    "    temp = np.unique(np.array(temp))\n",
    "    return temp\n",
    "\n",
    "cls = class_aggregate(np.array(df))\n",
    "\n",
    "def val_replace(cls,dataset):\n",
    "    for i in range(len(cls)):\n",
    "        dataset = dataset.replace(cls[i],i)\n",
    "    return dataset\n",
    "\n",
    "df = val_replace(cls,df)\n",
    "\n",
    "## Iris Dataset Classification\n",
    "def gini(splits,classes):\n",
    "    total_rows = 0\n",
    "    final = 0\n",
    "    for i in range(len(splits)):\n",
    "        total_rows+=len(splits[i])\n",
    "    final = 0\n",
    "    for split in splits:\n",
    "        if len(split)==0:\n",
    "            continue\n",
    "        gscore = 0\n",
    "        for cls in classes:\n",
    "            p = [row[-1] for row in split].count(cls)/len(split)\n",
    "            gscore+=p*p\n",
    "        final+= (1-gscore)*(len(split)/total_rows)\n",
    "    return final\n",
    "## This needs to be done very carefully\n",
    "## Binary Splits\n",
    "def divide_data(dataset,feature,threshold):\n",
    "    new_data1 = []\n",
    "    new_data2 = []\n",
    "    for elem in dataset:\n",
    "        if elem[feature]<threshold:\n",
    "            new_data1.append(elem)\n",
    "        else:\n",
    "            new_data2.append(elem)\n",
    "    return new_data1, new_data2\n",
    "\n",
    "def best_split(dataset,classes):\n",
    "    best_so_far = np.inf\n",
    "    best_splits = 0\n",
    "    feature = np.inf\n",
    "    value_split = 1000\n",
    "    for i in range(len(dataset[0])-1):\n",
    "        for elem in dataset:\n",
    "            splits = divide_data(dataset,i,elem[i])\n",
    "            gscore = gini(splits,classes)\n",
    "            if gscore<best_so_far:\n",
    "                best_so_far = gscore\n",
    "                best_splits = splits\n",
    "                feature = i\n",
    "                value_split = elem[i]\n",
    "    return {'split':best_splits,'Feature':feature,'Value':value_split}\n",
    "\n",
    "\n",
    "def leaf_node(split):\n",
    "    cls = [elem[-1] for elem in split]\n",
    "    # Take Majority Vote\n",
    "    count = {}\n",
    "    for i in cls:\n",
    "        if i not in count:\n",
    "            count[i]=1\n",
    "        else:\n",
    "            count[i]+=1\n",
    "    return max(count, key = count.get)\n",
    "\n",
    "def partition(node, maxdepth, minsize, depth):\n",
    "    ## Each partition from above gives a node in essence.\n",
    "    lchild, rchild = node['split']\n",
    "    if not lchild or not rchild:\n",
    "        node['left']= leaf_node(lchild+rchild)\n",
    "        node['right'] = leaf_node(lchild+rchild)\n",
    "        return\n",
    "    if depth>maxdepth:\n",
    "        node['left'] = leaf_node(lchild)\n",
    "        node['right'] = leaf_node(rchild)\n",
    "        return\n",
    "    if len(lchild)<=minsize:\n",
    "        node['left'] = leaf_node(lchild)\n",
    "    else:\n",
    "        node['left'] = best_split(lchild,cls)\n",
    "        partition(node['left'],maxdepth,minsize, depth+1)\n",
    "    if len(rchild)<=minsize:\n",
    "        node['right'] = leaf_node(rchild)\n",
    "    else:\n",
    "        node['right'] = best_split(rchild,cls)\n",
    "        partition(node['right'],maxdepth,minsize,depth+1)\n",
    "        \n",
    "\n",
    "def tree_iris(dataset, maxdepth, minsize):\n",
    "    root = best_split(dataset,cls)\n",
    "    partition(root,maxdepth,minsize,1)\n",
    "    ## Printing the made Decision Tree\n",
    "    return root\n",
    "\n",
    "def predict(node, row):\n",
    "    if row[node['Feature']] < node['Value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "def class_aggregate(dataset):\n",
    "    temp = []\n",
    "    for i in range(len(dataset)):\n",
    "        temp.append(dataset[i][-1])\n",
    "    temp = np.unique(np.array(temp))\n",
    "    return temp\n",
    "\n",
    "cls = class_aggregate(np.array(df))\n",
    "\n",
    "def val_replace(cls,dataset):\n",
    "    for i in range(len(cls)):\n",
    "        dataset = dataset.replace(cls[i],i)\n",
    "    return dataset\n",
    "\n",
    "df = val_replace(cls,df)\n",
    "\n",
    "def accurate(test,tree):\n",
    "    temp = 0\n",
    "    for i in test:\n",
    "        val = predict(tree,i)\n",
    "        if i[-1]==val:\n",
    "            temp+=1\n",
    "    return temp/len(test)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (a) - Implementation of a Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We actualy have 4 features for the IRIS Dataset. We will build decision tree using only two of them. This is because of the general heuristic that is used of choosing $\\sqrt n$ features for each tree, where $n$ is the number of features, so that we avoid high correlation among the built trees. Since $4\\choose2$ = 6, we'll build 6 such decision trees for this particular case. \n",
    "We'll build a random forest this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(df,number=-1):\n",
    "    lstcol = df.columns.tolist()\n",
    "    lstcol.remove('Target')\n",
    "    possible = []\n",
    "    n_feature = int(np.sqrt(len(lstcol)))\n",
    "    if number<=1:\n",
    "        possible = []\n",
    "        for i in combinations(lstcol,n_feature):\n",
    "            possible.append(i)\n",
    "        tree_avg_accuracy = []\n",
    "        for i in possible:\n",
    "            index = []\n",
    "            for j in range(len(i)):\n",
    "                index.append(i[j])\n",
    "            index.append('Target')\n",
    "            ndf = df[index]\n",
    "            datas = np.array(ndf)\n",
    "            train, test = train_test_split(datas, test_size = 0.3)\n",
    "            tree = tree_iris(train,4,1)\n",
    "            tree_avg_accuracy.append(accurate(test,tree))\n",
    "    else:\n",
    "        tree_avg_accuracy = []\n",
    "        for n in range(number//len(lstcol)+1):\n",
    "            for i in combinations(lstcol,n_feature):\n",
    "                possible.append(i)\n",
    "            for i in possible:\n",
    "                index = []\n",
    "                for j in range(len(i)):\n",
    "                    index.append(i[j])\n",
    "                index.append('Target')\n",
    "                ndf = df[index]\n",
    "                datas = np.array(ndf)\n",
    "                train, test = train_test_split(datas, test_size = 0.3)\n",
    "                tree = tree_iris(train,4,1)\n",
    "                tree_avg_accuracy.append(accurate(test,tree))\n",
    "    return  np.array(tree_avg_accuracy).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 (b) Implementation of a Parallelised Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mp.Queue()\n",
    "def random_forest_parallel(df,number = -1):\n",
    "    lstcol = df.columns.tolist()\n",
    "    lstcol.remove('Target')\n",
    "    n_feature = int(np.sqrt(len(lstcol)))\n",
    "    if number<=1:\n",
    "        possible = []\n",
    "        for i in combinations(lstcol,n_feature):\n",
    "            possible.append(i)\n",
    "        tree_avg_accuracy = []\n",
    "        for i in possible:\n",
    "            index = []\n",
    "            for j in range(len(i)):\n",
    "                index.append(i[j])\n",
    "            index.append('Target')\n",
    "            ndf = df[index]\n",
    "            datas = np.array(ndf)\n",
    "            train, test = train_test_split(datas, test_size = 0.3)\n",
    "            tree = tree_iris(train,4,1)\n",
    "            tree_avg_accuracy.append(accurate(test,tree))\n",
    "    else:\n",
    "        tree_avg_accuracy = []\n",
    "        mp_ = []\n",
    "        possible = []\n",
    "        for n in range(number//len(lstcol)+1):\n",
    "            for i in combinations(lstcol,n_feature):\n",
    "                possible.append(i)\n",
    "            for i in possible:\n",
    "                index = []\n",
    "                for j in range(len(i)):\n",
    "                    index.append(i[j])\n",
    "                index.append('Target')\n",
    "                mp_.append(mp.Process(target=tree_perf,args=(index,df)))\n",
    "        for p in mp_:\n",
    "            p.start()\n",
    "        for p in mp_:\n",
    "            p.join()\n",
    "        results = [output.get() for p in mp_]\n",
    "        return np.array(results).mean()\n",
    "    return(np.array(tree_avg_accuracy).mean())\n",
    "     \n",
    "def tree_perf(index,df):\n",
    "    tree_avg_accuracy = []\n",
    "    ndf = df[index]\n",
    "    datas = np.array(ndf)\n",
    "    train, test = train_test_split(datas, test_size = 0.3)\n",
    "    tree = tree_iris(train,4,1)\n",
    "    tree_avg_accuracy.append(accurate(test,tree))\n",
    "    output.put( np.array(tree_avg_accuracy).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1 (c) Comparison between Serial and Parallelized Versions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_parallel = {}\n",
    "time_seq = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 91.11111111111111\n",
      "Time for Parallel Version 0.3876769542694092\n",
      "Accuracy 91.11111111111113\n",
      "Time for Parallel Version 0.9993574619293213\n",
      "Accuracy 91.1111111111111\n",
      "Time for Parallel Version 1.5262739658355713\n",
      "Accuracy 91.11111111111113\n",
      "Time for Parallel Version 2.7771573066711426\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,46,5):\n",
    "    start_time = time.time()\n",
    "    print('Accuracy',random_forest_parallel(df,i))\n",
    "    end_time = time.time()\n",
    "    print('Time for Parallel Version',end_time-start_time)\n",
    "    time_parallel[i] = end_time-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5,46,5):\n",
    "    start_time = time.time()\n",
    "    print('Accuracy',random_forest(df,i))\n",
    "    end_time = time.time()\n",
    "    print('Time for Sequential Version',end_time-start_time)\n",
    "    time_seq[i] = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time_seq.keys(),time_seq.values(),marker='.',c='b',label='Sequential')\n",
    "plt.plot(time_parallel.keys(),time_parallel.values(),marker = '.',c='r',label='Parallel')\n",
    "plt.title('Time taken in seconds v/s number of trees')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Time in seconds')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 (d) Random Forest on Biased IRIS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_iris(df,number=-1):\n",
    "    lstcol = df.columns.tolist()\n",
    "    lstcol.remove('Target')\n",
    "    possible = []\n",
    "    n_feature = int(np.sqrt(len(lstcol)))\n",
    "    if number<=1:\n",
    "        possible = []\n",
    "        for i in combinations(lstcol,n_feature):\n",
    "            possible.append(i)\n",
    "        tree_avg_accuracy = []\n",
    "        for i in possible:\n",
    "            index = []\n",
    "            for j in range(len(i)):\n",
    "                index.append(i[j])\n",
    "            index.append('Target')\n",
    "            ndf = df[index]\n",
    "            datas = np.array(ndf)\n",
    "            train = datas[:105]\n",
    "            test =  datas[105:]\n",
    "            tree = tree_iris(train,4,1)\n",
    "            tree_avg_accuracy.append(accurate(test,tree))\n",
    "    else:\n",
    "        tree_avg_accuracy = []\n",
    "        for n in range(number//len(lstcol)+1):\n",
    "            for i in combinations(lstcol,n_feature):\n",
    "                possible.append(i)\n",
    "            for i in possible:\n",
    "                index = []\n",
    "                for j in range(len(i)):\n",
    "                    index.append(i[j])\n",
    "                index.append('Target')\n",
    "                ndf = df[index]\n",
    "                datas = np.array(ndf)\n",
    "                train = datas[:105]\n",
    "                test = datas[105:]\n",
    "                tree = tree_iris(train,4,1)\n",
    "                tree_avg_accuracy.append(accurate(test,tree))\n",
    "    return  np.array(tree_avg_accuracy).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest Accuracy is ',random_forest_iris(df,20))\n",
    "print('Decision Tree Accuracy is',accurate(np.array(df[105:]),tree_iris(np.array(df[:105]),4,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 (e) 5-Fold Cross Validation and Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I am getting \"Too Many Open Files\", when the number of decision trees I need to grow exceeds 45. Therefore I am only comparing <=45\n",
    "#### I am taking the tuple (1,5,10,20,30,45) for all testing purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From my previous assignment -- Here is the Cross Validation and Nested Cross Validation\n",
    "* I am implementing them without shuffling the dataset. Shuffling can also be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## IF DECISION TREE, ,DT = 1, else anything apart from 1 for Random Forests\n",
    "def kfold_cross_validation(df,dt=1):\n",
    "    if dt==1:\n",
    "        dataset = np.array(df)\n",
    "        avg_acc = []\n",
    "        for i in range(5):\n",
    "            test = dataset[30*i:30*(i+1)]\n",
    "            if 30*(i+1)+120<=150:\n",
    "                train = dataset[30*(i+1):]\n",
    "            else:\n",
    "                train1 = dataset[0:30*(i+1)-30]\n",
    "                train2 = dataset[30*(i+1):]\n",
    "                train = np.append(train1,train2,axis=0)\n",
    "            tree = tree_iris(train,4,0)\n",
    "            avg_acc.append(accurate(test,tree))\n",
    "        return np.array(avg_acc).mean()\n",
    "    else:\n",
    "        rf_avg = []\n",
    "        dataset = df.copy()\n",
    "        lstcol = df.columns.tolist()\n",
    "        lstcol.remove('Target')\n",
    "        n_feature = int(np.sqrt(len(lstcol)))\n",
    "        dataset1= np.array(df)\n",
    "        possible = []\n",
    "        for i in combinations(lstcol,n_feature):\n",
    "            possible.append(i)\n",
    "        for i in possible:\n",
    "            tree_avg_accuracy = []\n",
    "            index = []\n",
    "            for j in range(len(i)):\n",
    "                index.append(i[j])\n",
    "            index.append('Target')\n",
    "            ndf = dataset[index]\n",
    "            datas = np.array(ndf)\n",
    "            for i in range(5):\n",
    "                test = datas[30*i:30*(i+1)]\n",
    "                if 30*(i+1)+120<=150:\n",
    "                    train = datas[30*(i+1):]\n",
    "                else:\n",
    "                    train1 = datas[0:30*(i+1)-30]\n",
    "                    train2 = datas[30*(i+1):]\n",
    "                    train = np.append(train1,train2,axis=0)\n",
    "                tree = tree_iris(train,4,1)\n",
    "                tree_avg_accuracy.append(accurate(test,tree))\n",
    "        rf_avg.append(np.array(tree_avg_accuracy).mean())\n",
    "        print('The accuracy on Random Forests with K-Fold Cross Validation is',np.array(rf_avg).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average cross validation accuracy for Decision Tree is 89.33 %\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_cross_validation(df,0)\n",
    "print('The Decision Tree accuracy is (5 Fold Cross Validation)',kfold_cross_validation(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Cross Validation to find optimum number of trees in random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
