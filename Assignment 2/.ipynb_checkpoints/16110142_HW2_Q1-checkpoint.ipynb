{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Random Forests (Parallelized and Sequential) from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_iris()['data']\n",
    "target = load_iris()['target']\n",
    "target[:50] = 0\n",
    "target[51:100] = 1\n",
    "target[100:] = 2\n",
    "df = pd.DataFrame(dataset)\n",
    "df = df.rename( columns={0: \"SL\", 1: \"SW\", 2:\"PL\",3:\"PW\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(Target=pd.Series(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree as used in Assignment 1 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def class_aggregate(dataset):\n",
    "    temp = []\n",
    "    for i in range(len(dataset)):\n",
    "        temp.append(dataset[i][-1])\n",
    "    temp = np.unique(np.array(temp))\n",
    "    return temp\n",
    "\n",
    "cls = class_aggregate(np.array(df))\n",
    "\n",
    "def val_replace(cls,dataset):\n",
    "    for i in range(len(cls)):\n",
    "        dataset = dataset.replace(cls[i],i)\n",
    "    return dataset\n",
    "\n",
    "df = val_replace(cls,df)\n",
    "\n",
    "## Iris Dataset Classification\n",
    "def gini(splits,classes):\n",
    "    total_rows = 0\n",
    "    final = 0\n",
    "    for i in range(len(splits)):\n",
    "        total_rows+=len(splits[i])\n",
    "    final = 0\n",
    "    for split in splits:\n",
    "        if len(split)==0:\n",
    "            continue\n",
    "        gscore = 0\n",
    "        for cls in classes:\n",
    "            p = [row[-1] for row in split].count(cls)/len(split)\n",
    "            gscore+=p*p\n",
    "        final+= (1-gscore)*(len(split)/total_rows)\n",
    "    return final\n",
    "## This needs to be done very carefully\n",
    "## Binary Splits\n",
    "def divide_data(dataset,feature,threshold):\n",
    "    new_data1 = []\n",
    "    new_data2 = []\n",
    "    for elem in dataset:\n",
    "        if elem[feature]<threshold:\n",
    "            new_data1.append(elem)\n",
    "        else:\n",
    "            new_data2.append(elem)\n",
    "    return new_data1, new_data2\n",
    "\n",
    "def best_split(dataset,classes):\n",
    "    best_so_far = np.inf\n",
    "    best_splits = 0\n",
    "    feature = np.inf\n",
    "    value_split = 1000\n",
    "    for i in range(len(dataset[0])-1):\n",
    "        for elem in dataset:\n",
    "            splits = divide_data(dataset,i,elem[i])\n",
    "            gscore = gini(splits,classes)\n",
    "            if gscore<best_so_far:\n",
    "                best_so_far = gscore\n",
    "                best_splits = splits\n",
    "                feature = i\n",
    "                value_split = elem[i]\n",
    "    return {'split':best_splits,'Feature':feature,'Value':value_split}\n",
    "\n",
    "\n",
    "def leaf_node(split):\n",
    "    cls = [elem[-1] for elem in split]\n",
    "    # Take Majority Vote\n",
    "    count = {}\n",
    "    for i in cls:\n",
    "        if i not in count:\n",
    "            count[i]=1\n",
    "        else:\n",
    "            count[i]+=1\n",
    "    return max(count, key = count.get)\n",
    "\n",
    "def partition(node, maxdepth, minsize, depth):\n",
    "    ## Each partition from above gives a node in essence.\n",
    "    lchild, rchild = node['split']\n",
    "    if not lchild or not rchild:\n",
    "        node['left']= leaf_node(lchild+rchild)\n",
    "        node['right'] = leaf_node(lchild+rchild)\n",
    "        return\n",
    "    if depth>maxdepth:\n",
    "        node['left'] = leaf_node(lchild)\n",
    "        node['right'] = leaf_node(rchild)\n",
    "        return\n",
    "    if len(lchild)<=minsize:\n",
    "        node['left'] = leaf_node(lchild)\n",
    "    else:\n",
    "        node['left'] = best_split(lchild,cls)\n",
    "        partition(node['left'],maxdepth,minsize, depth+1)\n",
    "    if len(rchild)<=minsize:\n",
    "        node['right'] = leaf_node(rchild)\n",
    "    else:\n",
    "        node['right'] = best_split(rchild,cls)\n",
    "        partition(node['right'],maxdepth,minsize,depth+1)\n",
    "        \n",
    "\n",
    "def tree_iris(dataset, maxdepth, minsize):\n",
    "    root = best_split(dataset,cls)\n",
    "    partition(root,maxdepth,minsize,1)\n",
    "    ## Printing the made Decision Tree\n",
    "    return root\n",
    "\n",
    "def predict(node, row):\n",
    "    if row[node['Feature']] < node['Value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "def class_aggregate(dataset):\n",
    "    temp = []\n",
    "    for i in range(len(dataset)):\n",
    "        temp.append(dataset[i][-1])\n",
    "    temp = np.unique(np.array(temp))\n",
    "    return temp\n",
    "\n",
    "cls = class_aggregate(np.array(df))\n",
    "\n",
    "def val_replace(cls,dataset):\n",
    "    for i in range(len(cls)):\n",
    "        dataset = dataset.replace(cls[i],i)\n",
    "    return dataset\n",
    "\n",
    "df = val_replace(cls,df)\n",
    "\n",
    "def accurate(test,tree):\n",
    "    temp = 0\n",
    "    for i in test:\n",
    "        val = predict(tree,i)\n",
    "        if i[-1]==val:\n",
    "            temp+=1\n",
    "    return temp/len(test)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (a) - Implementation of a Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We actualy have 4 features for the IRIS Dataset. We will build decision tree using only two of them. This is because of the general heuristic that is used of choosing $\\sqrt n$ features for each tree, where $n$ is the number of features, so that we avoid high correlation among the built trees. Since $4\\choose2$ = 6, we'll build 6 such decision trees for this particular case. \n",
    "We'll build a random forest this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(df,number=-1):\n",
    "    lstcol = df.columns.tolist()\n",
    "    lstcol.remove('Target')\n",
    "    possible = []\n",
    "    n_feature = int(np.sqrt(len(lstcol)))\n",
    "    if number<=1:\n",
    "        possible = []\n",
    "        for i in combinations(lstcol,n_feature):\n",
    "            possible.append(i)\n",
    "        tree_avg_accuracy = []\n",
    "        for i in possible:\n",
    "            index = []\n",
    "            for j in range(len(i)):\n",
    "                index.append(i[j])\n",
    "            index.append('Target')\n",
    "            ndf = df[index]\n",
    "            datas = np.array(ndf)\n",
    "            train, test = train_test_split(datas, test_size = 0.3)\n",
    "            tree = tree_iris(train,4,1)\n",
    "            tree_avg_accuracy.append(accurate(test,tree))\n",
    "    else:\n",
    "        tree_avg_accuracy = []\n",
    "        for n in range(number//len(lstcol)+1):\n",
    "            for i in combinations(lstcol,n_feature):\n",
    "                possible.append(i)\n",
    "            for i in possible:\n",
    "                index = []\n",
    "                for j in range(len(i)):\n",
    "                    index.append(i[j])\n",
    "                index.append('Target')\n",
    "                ndf = df[index]\n",
    "                datas = np.array(ndf)\n",
    "                train, test = train_test_split(datas, test_size = 0.3)\n",
    "                tree = tree_iris(train,4,1)\n",
    "                tree_avg_accuracy.append(accurate(test,tree))\n",
    "    return  np.array(tree_avg_accuracy).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 (b) Implementation of a Parallelised Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mp.Queue()\n",
    "def random_forest_parallel(df,number = -1):\n",
    "    lstcol = df.columns.tolist()\n",
    "    lstcol.remove('Target')\n",
    "    n_feature = int(np.sqrt(len(lstcol)))\n",
    "    if number<=1:\n",
    "        possible = []\n",
    "        for i in combinations(lstcol,n_feature):\n",
    "            possible.append(i)\n",
    "        tree_avg_accuracy = []\n",
    "        for i in possible:\n",
    "            index = []\n",
    "            for j in range(len(i)):\n",
    "                index.append(i[j])\n",
    "            index.append('Target')\n",
    "            ndf = df[index]\n",
    "            datas = np.array(ndf)\n",
    "            train, test = train_test_split(datas, test_size = 0.3)\n",
    "            tree = tree_iris(train,4,1)\n",
    "            tree_avg_accuracy.append(accurate(test,tree))\n",
    "    else:\n",
    "        tree_avg_accuracy = []\n",
    "        mp_ = []\n",
    "        possible = []\n",
    "        for n in range(number//len(lstcol)+1):\n",
    "            for i in combinations(lstcol,n_feature):\n",
    "                possible.append(i)\n",
    "            for i in possible:\n",
    "                index = []\n",
    "                for j in range(len(i)):\n",
    "                    index.append(i[j])\n",
    "                index.append('Target')\n",
    "                mp_.append(mp.Process(target=tree_perf,args=(index,df)))\n",
    "        for p in mp_:\n",
    "            p.start()\n",
    "        for p in mp_:\n",
    "            p.join()\n",
    "        results = [output.get() for p in mp_]\n",
    "        return np.array(results).mean()\n",
    "    return(np.array(tree_avg_accuracy).mean())\n",
    "     \n",
    "def tree_perf(index,df):\n",
    "    tree_avg_accuracy = []\n",
    "    ndf = df[index]\n",
    "    datas = np.array(ndf)\n",
    "    train, test = train_test_split(datas, test_size = 0.3)\n",
    "    tree = tree_iris(train,4,1)\n",
    "    tree_avg_accuracy.append(accurate(test,tree))\n",
    "    output.put( np.array(tree_avg_accuracy).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1 (c) Comparison between Serial and Parallelized Versions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_parallel = {}\n",
    "time_seq = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 84.44444444444444\n",
      "Time for Parallel Version 0.34346818923950195\n",
      "Accuracy 84.44444444444444\n",
      "Time for Parallel Version 0.678170919418335\n",
      "Accuracy 84.44444444444444\n",
      "Time for Parallel Version 1.3618111610412598\n",
      "Accuracy 84.44444444444446\n",
      "Time for Parallel Version 3.372708797454834\n",
      "Accuracy 84.44444444444444\n",
      "Time for Parallel Version 3.538914680480957\n",
      "Accuracy 84.44444444444444\n",
      "Time for Parallel Version 4.130971908569336\n",
      "Accuracy 84.44444444444444\n",
      "Time for Parallel Version 5.7029948234558105\n",
      "Accuracy 84.44444444444444\n",
      "Time for Parallel Version 9.319095611572266\n",
      "Accuracy 84.44444444444444\n",
      "Time for Parallel Version 12.361685276031494\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,46,5):\n",
    "    start_time = time.time()\n",
    "    print('Accuracy',random_forest_parallel(df,i))\n",
    "    end_time = time.time()\n",
    "    print('Time for Parallel Version',end_time-start_time)\n",
    "    time_parallel[i] = end_time-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 89.13580246913581\n",
      "Time for Sequential Version 0.7742679119110107\n",
      "Accuracy 90.4320987654321\n",
      "Time for Sequential Version 1.619866132736206\n",
      "Accuracy 89.33333333333331\n",
      "Time for Sequential Version 2.186976909637451\n",
      "Accuracy 89.34744268077601\n",
      "Time for Sequential Version 4.417584180831909\n",
      "Accuracy 89.35185185185185\n",
      "Time for Sequential Version 5.473206520080566\n",
      "Accuracy 89.34156378600822\n",
      "Time for Sequential Version 6.962556838989258\n",
      "Accuracy 89.30041152263374\n",
      "Time for Sequential Version 8.871268033981323\n",
      "Accuracy 89.40516273849607\n",
      "Time for Sequential Version 13.910229444503784\n",
      "Accuracy 89.25451092117758\n",
      "Time for Sequential Version 15.246434926986694\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,46,5):\n",
    "    start_time = time.time()\n",
    "    print('Accuracy',random_forest(df,i))\n",
    "    end_time = time.time()\n",
    "    print('Time for Sequential Version',end_time-start_time)\n",
    "    time_seq[i] = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdda897a470>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time_seq.keys(),time_seq.values(),marker='.',c='b',label='Sequential')\n",
    "plt.plot(time_parallel.keys(),time_parallel.values(),marker = '.',c='r',label='Parallel')\n",
    "plt.title('Time taken in seconds v/s number of trees')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Time in seconds')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 (d) Random Forest on Biased IRIS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_iris(df,number=-1):\n",
    "    lstcol = df.columns.tolist()\n",
    "    lstcol.remove('Target')\n",
    "    possible = []\n",
    "    n_feature = int(np.sqrt(len(lstcol)))\n",
    "    if number<=1:\n",
    "        possible = []\n",
    "        for i in combinations(lstcol,n_feature):\n",
    "            possible.append(i)\n",
    "        tree_avg_accuracy = []\n",
    "        for i in possible:\n",
    "            index = []\n",
    "            for j in range(len(i)):\n",
    "                index.append(i[j])\n",
    "            index.append('Target')\n",
    "            ndf = df[index]\n",
    "            datas = np.array(ndf)\n",
    "            train = datas[:105]\n",
    "            test =  datas[105:]\n",
    "            tree = tree_iris(train,4,1)\n",
    "            tree_avg_accuracy.append(accurate(test,tree))\n",
    "    else:\n",
    "        tree_avg_accuracy = []\n",
    "        for n in range(number//len(lstcol)+1):\n",
    "            for i in combinations(lstcol,n_feature):\n",
    "                possible.append(i)\n",
    "            for i in possible:\n",
    "                index = []\n",
    "                for j in range(len(i)):\n",
    "                    index.append(i[j])\n",
    "                index.append('Target')\n",
    "                ndf = df[index]\n",
    "                datas = np.array(ndf)\n",
    "                train = datas[:105]\n",
    "                test = datas[105:]\n",
    "                tree = tree_iris(train,4,1)\n",
    "                tree_avg_accuracy.append(accurate(test,tree))\n",
    "    return  np.array(tree_avg_accuracy).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy is  62.96296296296296\n",
      "Decision Tree Accuracy is 73.33333333333333\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Accuracy is ',random_forest_iris(df,20))\n",
    "print('Decision Tree Accuracy is',accurate(np.array(df[105:]),tree_iris(np.array(df[:105]),4,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 (e) 5-Fold Cross Validation and Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I am getting \"Too Many Open Files\", when the number of decision trees I need to grow exceeds 45. Therefore I am only comparing <=45\n",
    "#### I am taking the tuple (1,5,10,20,30,45) for all testing purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From my previous assignment -- Here is the Cross Validation and Nested Cross Validation\n",
    "* I am implementing them without shuffling the dataset. Shuffling can also be done.\n",
    "* Also, if the second argument to the function $dt$ decides if we're doing RF or DT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## IF DECISION TREE, ,DT = 1, else anything apart from 1 for Random Forests\n",
    "def kfold_cross_validation(df,dt=1):\n",
    "    if dt==1:\n",
    "        dataset = np.array(df)\n",
    "        avg_acc = []\n",
    "        for i in range(5):\n",
    "            test = dataset[30*i:30*(i+1)]\n",
    "            if 30*(i+1)+120<=150:\n",
    "                train = dataset[30*(i+1):]\n",
    "            else:\n",
    "                train1 = dataset[0:30*(i+1)-30]\n",
    "                train2 = dataset[30*(i+1):]\n",
    "                train = np.append(train1,train2,axis=0)\n",
    "            tree = tree_iris(train,4,0)\n",
    "            avg_acc.append(accurate(test,tree))\n",
    "        return np.array(avg_acc).mean()\n",
    "    else:\n",
    "        rf_avg = []\n",
    "        dataset = df.copy()\n",
    "        lstcol = df.columns.tolist()\n",
    "        lstcol.remove('Target')\n",
    "        n_feature = int(np.sqrt(len(lstcol)))\n",
    "        dataset1= np.array(df)\n",
    "        possible = []\n",
    "        for i in combinations(lstcol,n_feature):\n",
    "            possible.append(i)\n",
    "        for i in possible:\n",
    "            tree_avg_accuracy = []\n",
    "            index = []\n",
    "            for j in range(len(i)):\n",
    "                index.append(i[j])\n",
    "            index.append('Target')\n",
    "            ndf = dataset[index]\n",
    "            datas = np.array(ndf)\n",
    "            for i in range(5):\n",
    "                test = datas[30*i:30*(i+1)]\n",
    "                if 30*(i+1)+120<=150:\n",
    "                    train = datas[30*(i+1):]\n",
    "                else:\n",
    "                    train1 = datas[0:30*(i+1)-30]\n",
    "                    train2 = datas[30*(i+1):]\n",
    "                    train = np.append(train1,train2,axis=0)\n",
    "                tree = tree_iris(train,4,1)\n",
    "                tree_avg_accuracy.append(accurate(test,tree))\n",
    "        rf_avg.append(np.array(tree_avg_accuracy).mean())\n",
    "        print('The accuracy on Random Forests with K-Fold Cross Validation is',np.array(rf_avg).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average cross validation accuracy for Decision Tree is 89.33 %\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on Random Forests with K-Fold Cross Validation is 92.0\n",
      "The Decision Tree accuracy is (5 Fold Cross Validation) 89.33333333333334\n"
     ]
    }
   ],
   "source": [
    "kfold_cross_validation(df,0)\n",
    "print('The Decision Tree accuracy is (5 Fold Cross Validation)',kfold_cross_validation(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Cross Validation to find optimum number of trees in random forests\n",
    " I am reusing my code from Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cross_validation(df,dt=1):\n",
    "    if dt==1:\n",
    "        print('here')\n",
    "        dataset = np.array(df)\n",
    "        for i in range(5):\n",
    "            test = dataset[30*i:30*(i+1)]\n",
    "            if 30*(i+1)+120<=150:\n",
    "                train = dataset[30*(i+1):]\n",
    "            else:\n",
    "                train1 = dataset[0:30*(i+1)-30]\n",
    "                train2 = dataset[30*(i+1):]\n",
    "                train = np.append(train1,train2,axis=0)\n",
    "            accuracy_validation = {}\n",
    "            for depth in range(1,11):\n",
    "                s = 0\n",
    "                for j in range(4):\n",
    "                    validation = train[30*j:30*(j+1)]\n",
    "                    train_1 = train[30*(j+1):]\n",
    "                    train_2 = train[0:30*(j+1)-30]\n",
    "                    train_ = np.append(train_1,train_2,axis = 0)\n",
    "                    tree = tree_iris(train_,depth,0)\n",
    "                    s+=(accurate(validation,tree))\n",
    "                accuracy_validation[depth] = s/4\n",
    "            value = max(accuracy_validation, key = accuracy_validation.get)\n",
    "            tree = tree_iris(train,value,0)\n",
    "            print(\"Accuracy is,\",accurate(test,tree), \" for iteration\",i+1, \". The depth of the optimal tree is \",value)\n",
    "    else:\n",
    "        dataset = df.copy()\n",
    "        for i in range(5):\n",
    "            test = dataset[30*i:30*(i+1)]\n",
    "            if 30*(i+1)+120<=150:\n",
    "                train = dataset[30*(i+1):]\n",
    "            else:\n",
    "                train1 = dataset[0:30*(i+1)-30]\n",
    "                train2 = dataset[30*(i+1):]\n",
    "                train = np.append(train1,train2,axis=0)\n",
    "                valid_score = {}\n",
    "                for number_of_trees in [5,10,20]:\n",
    "                    print(number_of_trees)\n",
    "                    s = 0\n",
    "                    for j in range(4):\n",
    "                        validation = train[30*j:30*(j+1)]\n",
    "                        train_1 = train[30*(j+1):]\n",
    "                        train_2 = train[0:30*(j+1)-30]\n",
    "                        train_ = np.append(train_1,train_2,axis = 0)\n",
    "                        s+=random_forest_kf(df,train_,validation,number_of_trees)\n",
    "                    valid_score[number_of_trees] = s/4\n",
    "                value = max(valid_score,key=valid_score.get)\n",
    "                print('The # of trees is ',value,' and the score is ',random_forest_kf(df,train,test,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_kf(df,train_,test_,number):\n",
    "    lstcol = df.columns.tolist()\n",
    "    lstcol.remove('Target')\n",
    "    possible = []\n",
    "    n_feature = int(np.sqrt(len(lstcol)))\n",
    "    if number<=1:\n",
    "        possible = []\n",
    "        for i in combinations(lstcol,n_feature):\n",
    "            possible.append(i)\n",
    "        tree_avg_accuracy = []\n",
    "        for i in possible:\n",
    "            index = []\n",
    "            for j in range(len(i)):\n",
    "                index.append(i[j])\n",
    "            index.append('Target')\n",
    "            train = train_\n",
    "            #datas = np.array(ndf)\n",
    "            test = test_\n",
    "            #train = np.array(train_)\n",
    "            #test = np.array(test_)\n",
    "            #train, test = train_test_split(datas, test_size = 0.3)\n",
    "            tree = tree_iris(train,4,1)\n",
    "            tree_avg_accuracy.append(accurate(test,tree))\n",
    "        return np.array(tree_avg_accuracy).mean()\n",
    "    else:\n",
    "        tree_avg_accuracy = []\n",
    "        #print(number//len(lstcol))\n",
    "        for n in range(number//len(lstcol)+1):\n",
    "            for i in combinations(lstcol,n_feature):\n",
    "                possible.append(i)\n",
    "            for i in possible:\n",
    "                index = []\n",
    "                for j in range(len(i)):\n",
    "                    index.append(i[j])\n",
    "                index.append('Target')\n",
    "                print(train_)\n",
    "                tree = tree_iris(train_,4,1)\n",
    "                tree_avg_accuracy.append(accurate(test_,tree))\n",
    "            #print(tree_avg_accuracy)\n",
    "        return np.array(tree_avg_accuracy).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
